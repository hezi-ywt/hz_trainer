# 超轻量级DMD训练配置文件 - 最大化节约显存

model:
  model_name: "NextDiT_2B_GQA_patch2_Adaln_Refiner"
  model_path: "/mnt/huggingface/Lumina-Image-2.0"
  vae_path: "/mnt/huggingface/Neta-Lumina/VAE/ae.safetensors"
  text_encoder_path: "/mnt/huggingface/Neta-Lumina/Text Encoder/gemma_2_2b_fp16.safetensors"
  init_from: "/mnt/huggingface/Neta-Lumina/Unet/neta-lumina-v1.0.safetensors"
  use_ema: false
  use_fake_model: false
  use_real_model: true  # 只使用real_model

advanced:
  use_ema: false
  vae_encode_batch_size: 1

data:
  train_data_dir: "/mnt/hz_trainer/batch_output"
  val_data_dir: "/mnt/hz_trainer/batch_output_20250827_002903"
  max_train_samples: 50  # 极少量样本用于测试
  max_val_samples: 10

trainer:
  batch_size: 1
  learning_rate: 1e-4
  weight_decay: 0.01
  max_epochs: 5  # 极少量epoch
  num_workers: 0  # 不使用多进程
  grad_clip: 1.0
  checkpoint_dir: "./checkpoints"
  log_dir: "./logs"
  precision: "bf16-mixed"  # 混合精度
  accumulate_grad_batches: 16  # 大量梯度累积
  # 显存优化设置
  strategy: "ddp_find_unused_parameters_false"
  sync_batchnorm: false
  enable_progress_bar: false
  enable_checkpointing: true
  enable_logging: true
  log_every_n_steps: 20  # 极少日志

generation:
  image_height: 256  # 极小图像尺寸
  image_width: 256
  steps: 10  # 极少推理步数
  guidance_scale: 5.0
  cfg_trunc_ratio: 1.0
  seed: null
  discrete_flow_shift: 6.0
  renorm_cfg: 1.0

k_diffusion:
  use_k_diffusion: true
  sampler: "euler_ancestral_RF"
  scheduler_func: "linear_quadratic_schedule"

output:
  output_dir: "./output"



